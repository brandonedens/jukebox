#!/usr/bin/env python
# Brandon Edens
# 2010-01-30
# Copyright (C) 2010 Brandon Edens <brandon@as220.org>
#
"""
Scrape images from top hits on google image search.
"""

###############################################################################
## Imports
###############################################################################

import logging
import re
import sys

from BeautifulSoup import BeautifulSoup
import cookielib
import mechanize


###############################################################################
## Constants
###############################################################################

GOOGLE_IMAGE_URL = 'http://images.google.com/'

LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"


###############################################################################
## Functions
###############################################################################

def browser_setup():
    # Create a browser.
    br = mechanize.Browser()

    # Cookie Jar
    cj = cookielib.LWPCookieJar()
    br.set_cookiejar(cj)

    # Browser options
    br.set_handle_equiv(True)
    br.set_handle_gzip(True)
    br.set_handle_redirect(True)
    br.set_handle_referer(True)
    br.set_handle_robots(False)

    # Follows refresh 0 but not hangs on refresh > 0
    br.set_handle_refresh(mechanize._http.HTTPRefreshProcessor(), max_time=1)

    # Debugging messages?
    #br.set_debug_http(True)
    #br.set_debug_redirects(True)
    #br.set_debug_responses(True)

    # User-Agent
    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]

    return br

def google_image_search(br, search_terms):

    # Open the google images page.
    res = br.open(GOOGLE_IMAGE_URL)

    # Select the image search form.
    br.select_form(nr=0)
    br.form['q'] = search_terms
    res = br.submit()
    data = res.get_data()

    # Find all picture links
    soup = BeautifulSoup(data)
    images = soup.findAll('img')
    links = []
    for img in images:
        search = re.search('gstatic.com', img['src'])
        if search:
            link = img['src']
            links.append('http://'+link.split(':http://')[1])
    return links

def main(search_terms):

    br = browser_setup()
    links = google_image_search(br, quoted_terms)
    files = []
    for link in links:
        f = br.retrieve(link)[0]
        files.append(f)
    return files


###############################################################################
## Statements
###############################################################################

if __name__ == '__main__':
    # Setup logging.
    logging.basicConfig(level=logging.DEBUG, format=LOG_FORMAT)
    search_terms = sys.argv[1:]

    unquoted_terms = (" ".join(search_terms))
    logging.debug("unquoted terms are: %s" % unquoted_terms)
    quoted_terms = '"'+unquoted_terms+'"'
    logging.debug("quoted terms are: %s" % quoted_terms)

    # Run the main method
    main(quoted_terms)

